#!/opt/opscode/embedded/bin/ruby
#
# Author:: Mark Anderson <mark@opscode.com>
# Cookbook Name:: couchdb
# Recipe:: default
#
# Copyright 2010-2011, Opscode, Inc
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

require 'net/http'
require 'find'
require 'rubygems'
require 'json'
require 'getoptlong'

# Returns true if we are running on a tier/standalone or if
# we are the master in an HA pair.
def should_run?
  if is_ha?
    is_keepalive_master?
  else
    true
  end
end

def running_config
  @running_config ||= begin
                        JSON.parse(File.read("/etc/opscode/chef-server-running.json"))
                      end
end

def is_ha?
  running_config['private_chef']['topology'] == "ha"
end

def is_keepalive_master?
  begin
    File.read("<%= node['private_chef']['keepalived']['dir'] %>/current_cluster_status").chomp == "master"
  rescue Errno::ENOENT
    false
  end
end

def uri_x(v)
  URI.escape(v.to_s, Regexp.new("[^#{URI::PATTERN::UNRESERVED}]"))
end

def mk_query(x) 
  if (x) 
    ((x.keys).map { |k| "#{k}=#{uri_x(x[k])}" }).join('&')
  else
    nil
  end
end

def mk_json_query(url,query=nil,verbose=false) 
  urlstr = if (url.class == Array) 
             url.join('/')
           else
             url
           end

  uri = URI.parse(urlstr + (query ? "?#{mk_query(query)}" : ""))

  puts "Querying #{uri}" if (verbose)
  req = Net::HTTP::Get.new(uri.request_uri)
  response = Net::HTTP.new(uri.host,uri.port).start {|http| http.request(req) }
  list = JSON.parse(response.body,:create_additions=>false) #, :symbolize_names=>true)
end

def mk_json_query_partial_id(url,id,verbose=false)
  query = {:startkey_docid=>id, :endkey_docid=>id.next}
  mk_json_query(url,query,verbose)
end

def mk_json_query_partial_key(url,id,verbose=false)
  query = {:startkey=>"\"#{id}\"", :endkey=>"\"#{id.next}\""}
  mk_json_query(url,query,verbose)
end

class Array
  def shuffle!
    size.downto(1) { |n| push delete_at(rand(n)) }
    self
  end
end

class CouchCompactor
  attr_accessor :verbose, :dryrun
  attr_accessor :server, :sleeptime, :couch_data_dir, :min_size, :rev_count, :db_compact_count_limit
  attr_accessor :acc_before, :acc_after
  attr_accessor :dbs, :dbages, :dbseq, :dbvmin, :db_sizes
  attr_accessor :skip_dbs

  def initialize(server)
    @db_compact_count_limit = -1
    @verbose = false
    @dryrun = false
    @server = server
    @rev_count = 1
    @couch_data_dir = '<%= File.join(node['private_chef']['couchdb']['dir'], 'db') %>'
    @sleeptime = 2
    @min_size = 1024*1000
    @skip_dbs = {}
    parse_args

    puts "Using server #{@server}"

    @dbs = get_db_list()
    @acc_before = 0
    @acc_after = 0
    @dbages = {}
    @dbseq = {}
    @dbvmin = {}
    @db_sizes = Hash.new(0)
    nil
  end

  def parse_args()
    @opts = GetoptLong.new(
                           [ '--verbose', '-v', GetoptLong::NO_ARGUMENT ],
                           [ '--skip_dbs', '-s', GetoptLong::REQUIRED_ARGUMENT ],
                           [ '--couch-data-dir', GetoptLong::REQUIRED_ARGUMENT ],
                           [ '--couch-url', GetoptLong::REQUIRED_ARGUMENT ],
                           [ '--max-dbs', '-m', GetoptLong::REQUIRED_ARGUMENT ]
                           )
    
    @opts.each do |opt,arg|
      case opt
      when '--verbose'
        self.verbose = true 
        puts "Verbose #{@verbose}"
      when '--skip_dbs'
        arg.split(/\s*,\s*/).each { |e| @skip_dbs[e]=true}
        puts "Skipping #{@skip_dbs.keys.join(', ')}"
      when '--couch-data-dir'
        self.couch_data_dir = arg
        puts "Data dir #{@couch_data_dir}"
      when '--couch-url'
        self.server = arg
      when '--max-dbs'
        self.db_compact_count_limit = arg.to_i - 1
      end
    end
  end
    
# url 'http://localhost:5984/authorization/_design/actors/_info'
# returns
# {"name":"actors","view_index":{"signature":"89bda8df032a72f431c7bdc0e6d50bc9","language":"javascript","disk_size":13918306,"updater_running":false,"compact_running":false,"waiting_commit":false,"waiting_clients":0,"update_seq":2679694,"purge_seq":0}}
  def get_design_info(db,view)
    mk_json_query([@server,db,view,'_info'])
  end

  def get_db_info(db)
    mk_json_query([@server,db])
  end


  def get_db_list()   
    mk_json_query([@server,'_all_dbs'])
  end

  def get_db_status(db)
    mk_json_query([@server,db],nil,false)
  end

  def get_stats()
    mk_json_query([@server, '_stats'])
  end
  
#curl 'http://localhost:5984/authorization/_all_docs?limit=10&startkey_docid=_design%2f&endkey_docid=_design0'
  def get_design_ids(db)
    query = {
      :startkey_docid=>"_design/",
      :endkey_docid=>"_design0",
      :limit=>100
    }
    list = mk_json_query([@server,db,"_all_docs"], query, false)['rows'].map { |x| x['id'] }
  end
  
  def get_views_list(db,design)
    design_doc = mk_json_query([@server,db,"_design",design], nil, false)
    design_doc["views"].keys
  end

  def runcmd (cmd)
    if (!@dryrun)
      STDOUT.puts "Exec: #{cmd}" if @verbose
      %x(#{cmd}) 
    else
      STDOUT.puts "Dryrun: #{cmd}" if @verbose
    end
  end

  def sleep_and_poll(task, wait)
    STDOUT.write("#{task} waiting #{wait}s per dot ") if @verbose
    while (true)
      if !yield
        STDOUT.puts "" if @verbose
        return
      end
      sleep(wait)
      STDOUT.write "." if @verbose
    end
  end
  
  def emit_time_and_change(task,secs,start_s,end_s)
    shrunk = (end_s*1.0 /start_s)-1.0
    STDOUT.puts format("%s took %2gs change %g%% (%g) (was %d now %d)",task, secs, 100.0*shrunk, 1+shrunk, start_s, end_s ) if @verbose
    @acc_before+= start_s
    @acc_after+=end_s
  end

# compact a db and wait until it's done
  def compact_db(db)
    start_t = Time.now.to_f
    
    begin 
      status = get_db_status(db)
      runcmd("curl -sS -X PUT -d '#{@rev_count}' '#{@server}/#{db}/_revs_limit'")
      
      start_s = status['disk_size']
      running = status['compact_running']
      
      if running
        STDOUT.puts("compact already running") if @verbose
      else
        runcmd("curl -H 'Content-Type: application/json' -sS -X POST '#{@server}/#{db}/_compact'")      
      end
      
      # wait for compact to finish....
      sleep_and_poll('Compacting db', @sleeptime) do
        status = get_db_status(db)
        running = status['compact_running']
      end
      # =>   rescue => e
      #    STDOUT.puts "Compact failed for #{@server} #{db}"
      #    throw e # fail permanently, because this might require user attention.
      
    end

    status = get_db_status(db)
    end_s =  status['disk_size']
    end_t = Time.now.to_f

    emit_time_and_change("Compact", end_t-start_t, start_s, end_s)
  end

  def get_design_ages(db)
    designs = get_design_ids(db)
    db_status = get_db_status(db)
    db_seqno = db_status['update_seq']
    
    lowest_seqno = db_seqno
    designs.each do |design|
      tries = 0
      begin 
        status = get_design_info(db,design)
        design_seqno = status['view_index']['update_seq'] 
      rescue
        tries+=1
        if tries < 3 
          retry
        else
          design_seqno = db_seqno
        end
      end
      lowest_seqno = design_seqno < lowest_seqno ? design_seqno : lowest_seqno
    end
    STDOUT.puts "#{db} #{db_seqno} #{lowest_seqno}" if @verbose

    @dbseq[db] = db_seqno
    @dbvmin[db] = lowest_seqno
    db_seqno-lowest_seqno
  end

  def sort_by_design_ages(dblist)
    @dbages = {}
    dblist.each { |x| @dbages[x] = get_design_ages(x) }
    dblist.sort { |x,y| @dbages[x] <=> @dbages[y] }
#    dblist.sort { |x,y| @dbages[y] <=> @dbages[x] } # smallest first.
  end


  def get_db_sizes(dir)

    @db_sizes = Hash.new(0)

    Find.find(dir) do |file|
      if File.file? file then
        size = File.size file
        if file =~ /\.([^\/].*)_design/
          dbname = $1
          @db_sizes[dbname]+= size
#          puts "design #{size} #{file} '#{dbname}'"
        end 
        if file =~ /([^\/]*).couch$/
          dbname = $1
          @db_sizes[dbname]+= size 
#          puts "couch #{size} #{file} '#{dbname}'"
        end
      end
    end
    @db_sizes
  end

#merge with above code
  def compact_design(db,design)
    STDOUT.puts "\n\tProcessing design #{design}" if @verbose
    
    start_t = Time.now.to_f
    
    db_status = get_db_status(db)
    db_seqno = db_status['update_seq']
#    sleep_and_poll('Gettings status', 0.5) do
      status = get_design_info(db,design)
#    end
    if (status.nil? ||  status.has_key?("error")) 
      # do something smarter here
      puts "skipping #{db} #{design} because status is unavailable"
      sleep(@sleeptime)
      return
    end
    running =  status && status['view_index'] && status['view_index']['compact_running'] == true
    design_seqno = status && status['view_index'] && status['view_index']['update_seq']
    start_s = status && status['view_index'] && status['view_index']['disk_size']
    STDOUT.puts "\tDB Seq #{db_seqno} Design Seq #{design_seqno} Design signature #{status['view_index']['signature']}" if @verbose

    designname = design.split('/')[1]    
    if (!running)
      runcmd("curl -H 'Content-Type: application/json' -sS -X POST '#{@server}/#{db}/_compact/#{designname}'")
    else
      STDOUT.puts "\tcompact already running"
    end

    sleep_and_poll("\tCompacting view",@sleeptime) do
      status = get_design_info(db,design)
      running = status && status['view_index'] && status['view_index']['compact_running'] == true
    end
    views = get_views_list(db,designname)

    if (false)
      # poke the view to trigger recomputation
      mk_json_query([@server,db,"_design", designname, "_view", views[0]], { :limit=>1 }, false)
      
      # check that view is caught up
      sleep_and_poll("\tRecomputing view",@sleeptime) do
        last_design_seqno = design_seqno
        status = get_design_info(db,design)
        design_seqno = status && status['view_index'] && status['view_index']['update_seq']
        delta = last_design_seqno - design_seqno
        #      STDOUT.puts "\tDB Seq #{db_seqno} Design Seq #{design_seqno} Delta #{delta} #{1.0*delta/db_seqno}" if @verbose
        (design_seqno < db_seqno)
      end
    end
    
    status = get_design_info(db,design)
    end_t = Time.now.to_f
    end_s = status['view_index']['disk_size']
    emit_time_and_change("\tCompact", end_t-start_t, start_s, end_s)
  end
  
  def compact_db_and_design(db)
    puts "="*60 if @verbose
    puts "Processing '#{db}'" if @verbose

    # don't waste time compacting tiny orgs (especially org-creator orgs)
    if (@db_sizes.has_key?(db) && @db_sizes[db] < @min_size)
      # using 
      puts "Skipping, too small #{db_sizes[db]}B" if @verbose
      return
    end
    status = get_db_status(db)
#    puts "Status: #{status}"
#    puts "Status: #{status['disk_size']}"
    if (status['disk_size'] < @min_size || status['update_seq'] < 75) 
      puts "Skipping, too small #{status['size']} Seq#:#{status['update_seq']}" if @verbose
      return
    end

    compact_db(db)
    runcmd("curl -H 'Content-Type: application/json' -sS -X POST '#{@server}/#{db}/_view_cleanup'")
    designs = get_design_ids(db)
    designs.each do |design|
      compact_design(db, design)
    end
    delta = @acc_before-@acc_after
    puts "Saved: #{sprintf('%2.4g',1.0*delta/(2**20))}MB (#{delta}B) (running total)" if @verbose
  end
    
  def compact_db_and_designs() 
    design_list = []
    dryrun = false
    verbose = true
    puts "Looking on #{@server}"
    
    fails = []

    tries = 0
    begin
      dbs = get_db_list().sort.uniq.select { |db| !@skip_dbs.has_key?(db) }
      if (File.directory? @couch_data_dir)
        puts "Proceeding in order of size (largest to smallest)"
        db_sizes = get_db_sizes(@couch_data_dir)
        dbs.sort! { |a,b| db_sizes[b] <=> db_sizes[a] }
#        dbs.sort! { |a,b| db_sizes[a] <=> db_sizes[b] }
      else
        dbs.shuffle!
      end
    rescue
      tries += 1
      retry if (tries < 3)
      raise
    end

    puts "Processing #{dbs.count} dbs on  #{@server}" if @verbose

    puts  "List of dbs: #{dbs[0..@db_compact_count_limit].join(", ")}"
    puts  "List of dbs skipped: #{@skip_dbs.keys.join(', ')}"

    dbs[0..@db_compact_count_limit].each do |db| 
      next if @skip_dbs.has_key?(db)
      tries = 0

      begin 
        compact_db_and_design(db)
      rescue
        puts "#{db} #{tries}\t#{$!}"
        tries += 1
        retry if (tries < 3)
        fails << db
      else
#        STDOUT.puts "No exceptions were raised from compact_db_and_designs for #{db}"
      ensure
#        STDOUT.puts "finishing the db loop for #{db.inspect}"
      end

    end
    delta = @acc_before-@acc_after
    puts "Saved: #{sprintf('%2.4f',1.0*delta/(2**20))}MB (#{delta}B) (running total)" 

    puts "Failed for databases #{fails.join(', ')}"
  end
end

def run 
  compact = CouchCompactor.new('http://localhost:5984')
  if (ARGV.length > 0) 
    compact.verbose = true
    ARGV.each { |db| compact.compact_db_and_design(db) }
  else
    compact.compact_db_and_designs()
  end
end

def setup_interactive()
  @@cpt = CouchCompactor.new(@@srv)
  @@cpt.verbose = true
  @@cpt.sleeptime = 2.0
end

if __FILE__ == $0
  begin
    if should_run?
      run
    else
      puts "Not running compaction. I'm the backup."
      exit 0
    end
  end
else
  @@srv = "http://localhost:5984"
  setup_interactive
end


